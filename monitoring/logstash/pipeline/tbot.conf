# T-Bot Logstash Pipeline Configuration
# Parses structured JSON logs from the trading system

input {
  # Read from JSON log files
  file {
    path => "/var/log/tbot/*.log"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb"
    codec => "json"
    type => "tbot-log"
  }

  # Optional: Accept logs via TCP (for real-time streaming)
  tcp {
    port => 5044
    codec => json_lines
    type => "tbot-tcp"
  }
}

filter {
  # Parse timestamp if it exists
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss"]
      target => "@timestamp"
    }
  }

  # Add trading-specific tags based on log content
  if [component] {
    mutate {
      add_tag => ["component-%{component}"]
    }
  }

  if [level] == "error" {
    mutate {
      add_tag => ["error"]
    }
  }

  if [level] == "warning" {
    mutate {
      add_tag => ["warning"]
    }
  }

  # Tag trading-critical events
  if [event] =~ /order|trade|position|risk/ {
    mutate {
      add_tag => ["trading-critical"]
    }
  }

  # Extract correlation IDs for request tracing
  if [correlation_id] {
    mutate {
      add_field => { "trace_id" => "%{correlation_id}" }
    }
  }

  # Parse error messages
  if [exc_info] {
    mutate {
      add_tag => ["exception"]
    }
  }

  # Add environment metadata
  mutate {
    add_field => {
      "system" => "tbot"
      "environment" => "${NODE_ENV:development}"
    }
  }
}

output {
  # Send to Elasticsearch with daily indices
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "tbot-logs-%{+YYYY.MM.dd}"

    # Create different indices based on log level for easier management
    # index => "tbot-%{level}-%{+YYYY.MM.dd}"
  }

  # Optional: Output to stdout for debugging
  # Uncomment during initial setup
  # stdout {
  #   codec => rubydebug
  # }
}
