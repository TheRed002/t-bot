# GPU-Enabled Dockerfile for T-Bot Trading System
# Optimized for ML/AI workloads with CUDA support

# ==============================================================================
# Base Stage - NVIDIA CUDA base with Python
# ==============================================================================
FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04 as base

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    PIP_DEFAULT_TIMEOUT=100 \
    DEBIAN_FRONTEND=noninteractive \
    TZ=UTC

# Install Python 3.10 and system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.10 \
    python3.10-dev \
    python3-pip \
    build-essential \
    curl \
    wget \
    gcc \
    g++ \
    cmake \
    git \
    libpq-dev \
    libssl-dev \
    libffi-dev \
    libblas-dev \
    liblapack-dev \
    libatlas-base-dev \
    libfreetype6-dev \
    libpng-dev \
    libhdf5-dev \
    pkg-config \
    # GPU monitoring tools
    nvidia-utils-520 \
    && ln -s /usr/bin/python3.10 /usr/bin/python \
    && rm -rf /var/lib/apt/lists/*

# Install TA-Lib from source
RUN cd /tmp && \
    wget -q http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz && \
    tar -xzf ta-lib-0.4.0-src.tar.gz && \
    cd ta-lib && \
    ./configure --prefix=/usr && \
    make -j$(nproc) && \
    make install && \
    cd / && \
    rm -rf /tmp/ta-lib* && \
    ldconfig

# Create non-root user
RUN groupadd --gid 1001 tbot && \
    useradd --uid 1001 --gid tbot --shell /bin/bash --create-home tbot

# ==============================================================================
# Builder Stage - Install Python dependencies
# ==============================================================================
FROM base as builder

WORKDIR /app

# Copy requirements file
COPY requirements.txt .

# Create virtual environment
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Upgrade pip and install base packages
RUN pip install --upgrade pip setuptools wheel

# Install GPU-enabled packages first
RUN pip install --upgrade \
    torch==2.1.0+cu121 \
    torchvision==0.16.0+cu121 \
    torchaudio==2.1.0+cu121 \
    --index-url https://download.pytorch.org/whl/cu121

# Install TensorFlow with CUDA support
RUN pip install --upgrade tensorflow[and-cuda]==2.15.0

# Install CuPy for GPU-accelerated arrays
RUN pip install --upgrade cupy-cuda12x

# Note: RAPIDS installation requires conda or special NVIDIA channels
# For production, consider using NVIDIA's official Docker images with RAPIDS pre-installed

# Install other requirements
RUN pip install -r requirements.txt

# Install additional GPU-optimized libraries
RUN pip install --upgrade \
    nvidia-ml-py3 \
    gpustat \
    py3nvml \
    xgboost==2.0.3 \
    lightgbm==4.3.0 --install-option=--gpu

# ==============================================================================
# Development Stage - For local development with GPU
# ==============================================================================
FROM base as development

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

WORKDIR /app

# Create necessary directories
RUN mkdir -p \
    logs/application \
    logs/system \
    logs/exchange \
    logs/database \
    logs/ml \
    logs/gpu \
    data/raw \
    data/processed \
    data/features \
    data/cache \
    models/trained_models \
    models/model_registry \
    models/gpu_cache \
    state/sessions \
    state/recovery \
    state/temp \
    backups/database \
    backups/config \
    reports/performance \
    reports/strategy \
    reports/risk \
    reports/gpu_metrics

# Set proper permissions
RUN chown -R tbot:tbot /app

# Switch to non-root user
USER tbot

# Expose port
EXPOSE 8000

# Set CUDA environment variables
ENV CUDA_VISIBLE_DEVICES=0 \
    CUDA_CACHE_PATH=/app/models/gpu_cache \
    TF_FORCE_GPU_ALLOW_GROWTH=true \
    TF_CPP_MIN_LOG_LEVEL=2

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Development command with auto-reload
CMD ["uvicorn", "src.web_interface.app:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

# ==============================================================================
# Production Stage - Optimized for production deployment with GPU
# ==============================================================================
FROM base as production

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

WORKDIR /app

# Copy application code with proper ownership
COPY --chown=tbot:tbot src/ ./src/
COPY --chown=tbot:tbot config/ ./config/
COPY --chown=tbot:tbot alembic.ini ./
COPY --chown=tbot:tbot pyproject.toml ./

# Create necessary directories
RUN mkdir -p \
    logs/application \
    logs/system \
    logs/exchange \
    logs/database \
    logs/ml \
    logs/gpu \
    data/raw \
    data/processed \
    data/features \
    data/cache \
    models/trained_models \
    models/model_registry \
    models/gpu_cache \
    state/sessions \
    state/recovery \
    state/temp \
    backups/database \
    backups/config \
    reports/performance \
    reports/strategy \
    reports/risk \
    reports/gpu_metrics && \
    chown -R tbot:tbot /app

# Switch to non-root user
USER tbot

# Expose port
EXPOSE 8000

# Set CUDA environment variables for production
ENV CUDA_VISIBLE_DEVICES=0 \
    CUDA_CACHE_PATH=/app/models/gpu_cache \
    TF_FORCE_GPU_ALLOW_GROWTH=true \
    TF_CPP_MIN_LOG_LEVEL=2 \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Health check with more appropriate timeout for production
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Production command with optimizations and GPU support
CMD ["uvicorn", "src.web_interface.app:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4", "--worker-class", "uvicorn.workers.UvicornWorker"]

# ==============================================================================
# Default target is production
# ==============================================================================
FROM production