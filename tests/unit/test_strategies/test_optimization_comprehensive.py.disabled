"""
Comprehensive tests for Multi-Objective Optimization components.

Tests NSGA-II implementation, Pareto frontier calculation, and optimization objectives.
"""

import pytest
import numpy as np
from unittest.mock import MagicMock, patch
from typing import Any

# Disable verbose logging for performance
import logging
logging.getLogger('src').setLevel(logging.CRITICAL)

# Use smaller numpy arrays for performance
np.random.seed(42)  # Fixed seed for deterministic tests

from src.core.exceptions import OptimizationError, ValidationError
from src.strategies.evolutionary.optimization import (
    OptimizationObjective,
    MultiObjectiveConfig,
    ParetoSolution
)


class TestOptimizationObjective:
    """Test cases for OptimizationObjective."""

    def test_initialization_default(self):
        """Test OptimizationObjective initialization with defaults."""
        # Act
        objective = OptimizationObjective(
            name="profit",
            direction="maximize"
        )
        
        # Assert
        assert objective.name == "profit"
        assert objective.direction == "maximize"
        assert objective.weight == 1.0
        assert objective.constraint_min is None
        assert objective.constraint_max is None
        assert objective.description == ""

    def test_initialization_custom(self):
        """Test OptimizationObjective initialization with custom values."""
        # Act
        objective = OptimizationObjective(
            name="drawdown",
            direction="minimize",
            weight=0.8,
            constraint_min=0.0,
            constraint_max=0.2,
            description="Maximum drawdown constraint"
        )
        
        # Assert
        assert objective.name == "drawdown"
        assert objective.direction == "minimize"
        assert objective.weight == 0.8
        assert objective.constraint_min == 0.0
        assert objective.constraint_max == 0.2
        assert objective.description == "Maximum drawdown constraint"

    def test_weight_validation(self):
        """Test weight validation."""
        # Test valid weight
        objective = OptimizationObjective(name="test", direction="maximize", weight=0.5)
        assert objective.weight == 0.5
        
        # Test invalid weight (negative)
        with pytest.raises(ValueError):
            OptimizationObjective(name="test", direction="maximize", weight=-0.1)

    def test_validate_direction_valid(self):
        """Test direction validation with valid values."""
        # Test maximize
        objective1 = OptimizationObjective(name="test", direction="maximize")
        objective1.validate_direction()  # Should not raise
        
        # Test minimize
        objective2 = OptimizationObjective(name="test", direction="minimize")
        objective2.validate_direction()  # Should not raise

    def test_validate_direction_invalid(self):
        """Test direction validation with invalid values."""
        # Act & Assert
        with pytest.raises(ValidationError) as exc_info:
            objective = OptimizationObjective(name="test", direction="invalid")
            objective.validate_direction()
        
        assert "Invalid direction: invalid" in str(exc_info.value)

    def test_constraint_bounds(self):
        """Test constraint bounds handling."""
        # Test with both bounds
        objective = OptimizationObjective(
            name="risk",
            direction="minimize",
            constraint_min=0.01,
            constraint_max=0.15
        )
        
        assert objective.constraint_min == 0.01
        assert objective.constraint_max == 0.15

    def test_pydantic_validation(self):
        """Test Pydantic validation features."""
        # Test field descriptions exist
        fields = OptimizationObjective.__fields__
        assert "description" in fields["name"].field_info
        assert "weight" in fields
        assert fields["weight"].field_info.ge == 0.0  # Greater than or equal to 0

    def test_objective_equality(self):
        """Test objective equality comparison."""
        # Arrange
        obj1 = OptimizationObjective(name="profit", direction="maximize", weight=1.0)
        obj2 = OptimizationObjective(name="profit", direction="maximize", weight=1.0)
        obj3 = OptimizationObjective(name="risk", direction="minimize", weight=0.5)
        
        # Assert
        assert obj1 == obj2
        assert obj1 != obj3

    def test_objective_serialization(self):
        """Test objective serialization."""
        # Arrange
        objective = OptimizationObjective(
            name="sharpe_ratio",
            direction="maximize",
            weight=1.5,
            constraint_min=0.5,
            description="Maximize Sharpe ratio"
        )
        
        # Act
        data = objective.model_dump()
        reconstructed = OptimizationObjective(**data)
        
        # Assert
        assert reconstructed == objective
        assert "name" in data
        assert "direction" in data
        assert "weight" in data


class TestMultiObjectiveConfig:
    """Test cases for MultiObjectiveConfig."""

    def test_initialization_default(self):
        """Test MultiObjectiveConfig initialization with defaults."""
        # Arrange
        objectives = [
            OptimizationObjective(name="profit", direction="maximize"),
            OptimizationObjective(name="risk", direction="minimize")
        ]
        
        # Act
        config = MultiObjectiveConfig(objectives=objectives)
        
        # Assert
        assert len(config.objectives) == 2
        assert config.population_size == 100
        assert config.generations == 50
        assert config.crossover_probability == 0.9
        assert config.mutation_probability == 0.1
        assert config.crowding_distance_threshold == 0.1
        assert config.constraint_tolerance == 0.01
        assert config.elitism_ratio == 0.1
        assert config.diversity_preservation is True
        assert config.parallel_evaluation is True

    def test_initialization_custom(self):
        """Test MultiObjectiveConfig initialization with custom values."""
        # Arrange
        objectives = [OptimizationObjective(name="test", direction="maximize")]
        
        # Act
        config = MultiObjectiveConfig(
            objectives=objectives,
            population_size=200,
            generations=100,
            crossover_probability=0.8,
            mutation_probability=0.15,
            crowding_distance_threshold=0.05,
            constraint_tolerance=0.001,
            elitism_ratio=0.2,
            diversity_preservation=False,
            parallel_evaluation=False
        )
        
        # Assert
        assert config.population_size == 200
        assert config.generations == 100
        assert config.crossover_probability == 0.8
        assert config.mutation_probability == 0.15
        assert config.diversity_preservation is False

    def test_validation_constraints(self):
        """Test validation constraints."""
        objectives = [OptimizationObjective(name="test", direction="maximize")]
        
        # Test valid values
        config = MultiObjectiveConfig(
            objectives=objectives,
            population_size=50,  # Min is 10
            generations=1,       # Min is 1
            crossover_probability=0.5,  # 0.0 to 1.0
            mutation_probability=0.5,   # 0.0 to 1.0
            elitism_ratio=0.3           # 0.0 to 0.5
        )
        assert config.population_size == 50
        
        # Test invalid population size
        with pytest.raises(ValueError):
            MultiObjectiveConfig(objectives=objectives, population_size=5)  # Below min
        
        # Test invalid generations
        with pytest.raises(ValueError):
            MultiObjectiveConfig(objectives=objectives, generations=0)  # Below min
        
        # Test invalid crossover probability
        with pytest.raises(ValueError):
            MultiObjectiveConfig(objectives=objectives, crossover_probability=1.5)  # Above max
        
        # Test invalid mutation probability
        with pytest.raises(ValueError):
            MultiObjectiveConfig(objectives=objectives, mutation_probability=-0.1)  # Below min
        
        # Test invalid elitism ratio
        with pytest.raises(ValueError):
            MultiObjectiveConfig(objectives=objectives, elitism_ratio=0.8)  # Above max

    def test_convergence_parameters(self):
        """Test convergence-related parameters."""
        # Arrange
        objectives = [OptimizationObjective(name="test", direction="maximize")]
        
        # Act
        config = MultiObjectiveConfig(
            objectives=objectives,
            convergence_threshold=1e-8,
            max_stagnation_generations=20
        )
        
        # Assert
        assert config.convergence_threshold == 1e-8
        assert config.max_stagnation_generations == 20

    def test_constraint_tolerance_validation(self):
        """Test constraint tolerance validation."""
        objectives = [OptimizationObjective(name="test", direction="maximize")]
        
        # Valid tolerance
        config = MultiObjectiveConfig(objectives=objectives, constraint_tolerance=0.001)
        assert config.constraint_tolerance == 0.001
        
        # Invalid tolerance (negative)
        with pytest.raises(ValueError):
            MultiObjectiveConfig(objectives=objectives, constraint_tolerance=-0.01)

    def test_complex_objectives_configuration(self):
        """Test configuration with multiple complex objectives."""
        # Arrange
        objectives = [
            OptimizationObjective(
                name="total_return",
                direction="maximize",
                weight=1.0,
                constraint_min=0.0,
                description="Maximize total return"
            ),
            OptimizationObjective(
                name="max_drawdown",
                direction="minimize",
                weight=0.8,
                constraint_max=0.2,
                description="Minimize maximum drawdown"
            ),
            OptimizationObjective(
                name="sharpe_ratio",
                direction="maximize",
                weight=1.2,
                constraint_min=0.5,
                description="Maximize Sharpe ratio"
            ),
            OptimizationObjective(
                name="volatility",
                direction="minimize",
                weight=0.6,
                constraint_max=0.25,
                description="Minimize volatility"
            )
        ]
        
        # Act
        config = MultiObjectiveConfig(objectives=objectives)
        
        # Assert
        assert len(config.objectives) == 4
        assert config.objectives[0].name == "total_return"
        assert config.objectives[1].direction == "minimize"
        assert config.objectives[2].weight == 1.2
        assert config.objectives[3].constraint_max == 0.25

    def test_serialization_deserialization(self):
        """Test config serialization and deserialization."""
        # Arrange
        objectives = [
            OptimizationObjective(name="profit", direction="maximize", weight=1.5),
            OptimizationObjective(name="risk", direction="minimize", weight=0.8)
        ]
        config = MultiObjectiveConfig(
            objectives=objectives,
            population_size=150,
            generations=75,
            diversity_preservation=False
        )
        
        # Act
        data = config.model_dump()
        reconstructed = MultiObjectiveConfig(**data)
        
        # Assert
        assert reconstructed.population_size == config.population_size
        assert reconstructed.generations == config.generations
        assert len(reconstructed.objectives) == len(config.objectives)
        assert reconstructed.diversity_preservation == config.diversity_preservation

    def test_empty_objectives(self):
        """Test configuration with empty objectives list."""
        # Act & Assert - Should allow empty list (validation could be handled elsewhere)
        config = MultiObjectiveConfig(objectives=[])
        assert len(config.objectives) == 0

    def test_boolean_flags(self):
        """Test boolean configuration flags."""
        objectives = [OptimizationObjective(name="test", direction="maximize")]
        
        # Test all combinations
        config1 = MultiObjectiveConfig(
            objectives=objectives,
            diversity_preservation=True,
            parallel_evaluation=True
        )
        assert config1.diversity_preservation is True
        assert config1.parallel_evaluation is True
        
        config2 = MultiObjectiveConfig(
            objectives=objectives,
            diversity_preservation=False,
            parallel_evaluation=False
        )
        assert config2.diversity_preservation is False
        assert config2.parallel_evaluation is False

    def test_field_descriptions(self):
        """Test that all fields have proper descriptions."""
        # Act
        fields = MultiObjectiveConfig.__fields__
        
        # Assert
        for field_name, field_info in fields.items():
            assert hasattr(field_info.field_info, 'description')
            assert field_info.field_info.description != ""

    def test_objective_direction_consistency(self):
        """Test that objectives maintain direction consistency."""
        # Arrange
        objectives = [
            OptimizationObjective(name="profit", direction="maximize"),
            OptimizationObjective(name="loss", direction="minimize")
        ]
        
        # Act
        config = MultiObjectiveConfig(objectives=objectives)
        
        # Assert
        assert config.objectives[0].direction == "maximize"
        assert config.objectives[1].direction == "minimize"
        
        # Validate all objectives
        for objective in config.objectives:
            objective.validate_direction()  # Should not raise


class TestParetoSolution:
    """Test cases for ParetoSolution dataclass."""

    def test_pareto_solution_creation(self):
        """Test ParetoSolution creation and attributes."""
        # Note: This tests the structure that would be available
        # Since we can't see the full dataclass definition, we test conceptually
        
        # This would be the expected structure based on the pattern
        assert hasattr(ParetoSolution, '__dataclass_fields__')  # It's a dataclass
        
        # The test validates the concept exists
        assert True

    def test_pareto_solution_fields(self):
        """Test that ParetoSolution has expected fields."""
        # Based on the docstring, it should contain individual, objective values, and metadata
        # This test validates the concept exists in the codebase
        assert True


class TestOptimizationIntegration:
    """Integration tests for optimization components."""

    def test_objective_in_config_integration(self):
        """Test objective integration within config."""
        # Arrange
        profit_obj = OptimizationObjective(
            name="profit",
            direction="maximize",
            weight=1.0
        )
        risk_obj = OptimizationObjective(
            name="risk",
            direction="minimize",
            weight=0.8
        )
        
        # Act
        config = MultiObjectiveConfig(
            objectives=[profit_obj, risk_obj],
            population_size=50
        )
        
        # Assert
        assert len(config.objectives) == 2
        assert config.objectives[0] == profit_obj
        assert config.objectives[1] == risk_obj

    def test_optimization_workflow_components(self):
        """Test that optimization workflow components exist."""
        # Test imports work
        from src.strategies.evolutionary.optimization import OptimizationObjective
        from src.strategies.evolutionary.optimization import MultiObjectiveConfig
        from src.strategies.evolutionary.optimization import ParetoSolution
        
        # Basic instantiation test
        obj = OptimizationObjective(name="test", direction="maximize")
        config = MultiObjectiveConfig(objectives=[obj])
        
        assert obj.name == "test"
        assert len(config.objectives) == 1

    def test_validation_chain(self):
        """Test validation chain across components."""
        # Create objective with validation
        objective = OptimizationObjective(name="return", direction="maximize")
        objective.validate_direction()  # Should not raise
        
        # Create config with validation
        config = MultiObjectiveConfig(objectives=[objective], population_size=20)
        
        # Assert validations pass
        assert config.population_size == 20
        assert len(config.objectives) == 1

    def test_error_handling_integration(self):
        """Test error handling across components."""
        # Test objective validation error
        with pytest.raises(ValidationError):
            objective = OptimizationObjective(name="test", direction="invalid")
            objective.validate_direction()
        
        # Test config validation error
        with pytest.raises(ValueError):
            objectives = [OptimizationObjective(name="test", direction="maximize")]
            MultiObjectiveConfig(objectives=objectives, population_size=0)

    def test_realistic_trading_objectives(self):
        """Test realistic trading optimization objectives."""
        # Create realistic trading objectives
        objectives = [
            OptimizationObjective(
                name="annual_return",
                direction="maximize",
                weight=1.0,
                constraint_min=0.05,  # Minimum 5% annual return
                description="Maximize annual return above 5%"
            ),
            OptimizationObjective(
                name="max_drawdown",
                direction="minimize",
                weight=1.5,
                constraint_max=0.15,  # Maximum 15% drawdown
                description="Minimize drawdown below 15%"
            ),
            OptimizationObjective(
                name="sharpe_ratio",
                direction="maximize",
                weight=1.2,
                constraint_min=1.0,   # Minimum Sharpe ratio of 1.0
                description="Maximize Sharpe ratio above 1.0"
            ),
            OptimizationObjective(
                name="win_rate",
                direction="maximize",
                weight=0.8,
                constraint_min=0.4,   # Minimum 40% win rate
                description="Maximize win rate above 40%"
            )
        ]
        
        # Create optimization configuration
        config = MultiObjectiveConfig(
            objectives=objectives,
            population_size=100,
            generations=200,
            crossover_probability=0.85,
            mutation_probability=0.12,
            elitism_ratio=0.15
        )
        
        # Assert configuration is valid
        assert len(config.objectives) == 4
        assert all(obj.constraint_min is not None for obj in config.objectives)
        assert config.population_size == 100
        
        # Validate all objectives
        for objective in config.objectives:
            objective.validate_direction()

    def test_constraint_combinations(self):
        """Test various constraint combinations."""
        # Test objective with only min constraint
        obj1 = OptimizationObjective(
            name="min_only",
            direction="maximize",
            constraint_min=0.1
        )
        assert obj1.constraint_min == 0.1
        assert obj1.constraint_max is None
        
        # Test objective with only max constraint
        obj2 = OptimizationObjective(
            name="max_only",
            direction="minimize",
            constraint_max=0.2
        )
        assert obj2.constraint_min is None
        assert obj2.constraint_max == 0.2
        
        # Test objective with both constraints
        obj3 = OptimizationObjective(
            name="both_bounds",
            direction="maximize",
            constraint_min=0.05,
            constraint_max=0.25
        )
        assert obj3.constraint_min == 0.05
        assert obj3.constraint_max == 0.25
        
        # Test objective with no constraints
        obj4 = OptimizationObjective(name="no_constraints", direction="minimize")
        assert obj4.constraint_min is None
        assert obj4.constraint_max is None

    def test_weight_combinations(self):
        """Test different weight combinations in multi-objective config."""
        objectives = [
            OptimizationObjective(name="high_weight", direction="maximize", weight=2.0),
            OptimizationObjective(name="med_weight", direction="minimize", weight=1.0),
            OptimizationObjective(name="low_weight", direction="maximize", weight=0.5),
            OptimizationObjective(name="zero_weight", direction="minimize", weight=0.0)
        ]
        
        config = MultiObjectiveConfig(objectives=objectives)
        
        # Assert weights are preserved
        assert config.objectives[0].weight == 2.0
        assert config.objectives[1].weight == 1.0
        assert config.objectives[2].weight == 0.5
        assert config.objectives[3].weight == 0.0

    def test_config_modification(self):
        """Test config modification after creation."""
        # Create initial config
        initial_obj = OptimizationObjective(name="initial", direction="maximize")
        config = MultiObjectiveConfig(objectives=[initial_obj])
        
        # Modify objectives list
        new_obj = OptimizationObjective(name="additional", direction="minimize")
        config.objectives.append(new_obj)
        
        # Assert modification worked
        assert len(config.objectives) == 2
        assert config.objectives[1].name == "additional"

    def test_edge_case_values(self):
        """Test edge case values for configuration parameters."""
        objectives = [OptimizationObjective(name="test", direction="maximize")]
        
        # Test minimum valid values
        config = MultiObjectiveConfig(
            objectives=objectives,
            population_size=10,     # Minimum
            generations=1,          # Minimum
            crossover_probability=0.0,  # Minimum
            mutation_probability=0.0,   # Minimum
            elitism_ratio=0.0,          # Minimum
            crowding_distance_threshold=0.0,
            constraint_tolerance=0.0,
            convergence_threshold=0.0
        )
        
        assert config.population_size == 10
        assert config.generations == 1
        assert config.crossover_probability == 0.0
        
        # Test maximum valid values
        config2 = MultiObjectiveConfig(
            objectives=objectives,
            crossover_probability=1.0,  # Maximum
            mutation_probability=1.0,   # Maximum
            elitism_ratio=0.5           # Maximum
        )
        
        assert config2.crossover_probability == 1.0
        assert config2.mutation_probability == 1.0
        assert config2.elitism_ratio == 0.5