"""
Tests for optimization repository to boost coverage.

This module provides basic tests for the repository functionality
to increase overall module coverage.
"""

import pytest
from unittest.mock import Mock, patch, AsyncMock
from datetime import datetime, timezone
from decimal import Decimal
from typing import Any
import uuid

from src.optimization.repository import OptimizationRepository
from src.optimization.core import OptimizationResult, OptimizationStatus


class TestOptimizationRepositoryBasic:
    """Test basic repository functionality."""

    @pytest.fixture
    def mock_session(self):
        """Create a mock async session."""
        session = AsyncMock()
        session.execute = AsyncMock()
        session.commit = AsyncMock()
        session.rollback = AsyncMock()
        session.close = AsyncMock()
        return session

    @pytest.fixture
    def repository(self, mock_session):
        """Create repository with mocked session."""
        repo = OptimizationRepository(session=mock_session, name="TestRepo")
        return repo

    @pytest.fixture
    def sample_optimization_result(self):
        """Create a sample optimization result."""
        return {
            "optimization_id": "test-opt-123",
            "algorithm_name": "brute_force",
            "optimal_parameters": {"param1": Decimal("0.15")},
            "optimal_objective_value": Decimal("1500.75"),
            "status": "completed",
            "created_at": datetime.now(timezone.utc),
            "updated_at": datetime.now(timezone.utc)
        }

    def test_repository_initialization(self):
        """Test repository initialization."""
        repo = OptimizationRepository(name="TestRepo")
        assert repo.name == "TestRepo"
        assert hasattr(repo, '_session')

    def test_repository_initialization_with_db_service(self, mock_session):
        """Test repository initialization with provided session."""
        repo = OptimizationRepository(
            session=mock_session,
            name="TestRepo"
        )
        assert repo._session is mock_session

    @pytest.mark.asyncio
    async def test_save_optimization_result_basic(self, repository, sample_optimization_result, mock_database_service):
        """Test basic optimization result saving."""
        mock_database_service.execute_query.return_value = None

        await repository.save_optimization_result(sample_optimization_result)

        mock_database_service.execute_query.assert_called_once()
        call_args = mock_database_service.execute_query.call_args
        assert "INSERT" in call_args[0][0].upper()

    @pytest.mark.asyncio
    async def test_get_optimization_result_by_id(self, repository, mock_database_service):
        """Test getting optimization result by ID."""
        mock_result = {
            "optimization_id": "test-123",
            "algorithm_name": "brute_force",
            "status": "completed"
        }
        mock_database_service.fetch_one.return_value = mock_result

        result = await repository.get_optimization_result("test-123")

        assert result == mock_result
        mock_database_service.fetch_one.assert_called_once()

    @pytest.mark.asyncio
    async def test_get_optimization_result_not_found(self, repository, mock_database_service):
        """Test getting optimization result that doesn't exist."""
        mock_database_service.fetch_one.return_value = None

        result = await repository.get_optimization_result("nonexistent")

        assert result is None

    @pytest.mark.asyncio
    async def test_list_optimization_results(self, repository, mock_database_service):
        """Test listing optimization results."""
        mock_results = [
            {"optimization_id": "test-1", "status": "completed"},
            {"optimization_id": "test-2", "status": "running"}
        ]
        mock_database_service.fetch_all.return_value = mock_results

        results = await repository.list_optimization_results()

        assert results == mock_results
        mock_database_service.fetch_all.assert_called_once()

    @pytest.mark.asyncio
    async def test_list_optimization_results_with_filters(self, repository, mock_database_service):
        """Test listing optimization results with filters."""
        mock_results = [{"optimization_id": "test-1", "status": "completed"}]
        mock_database_service.fetch_all.return_value = mock_results

        results = await repository.list_optimization_results(
            strategy_name="test_strategy",
            status="completed",
            limit=10,
            offset=0
        )

        assert results == mock_results
        call_args = mock_database_service.fetch_all.call_args
        assert "WHERE" in call_args[0][0]
        assert "LIMIT" in call_args[0][0]

    @pytest.mark.asyncio
    async def test_update_optimization_status(self, repository, mock_database_service):
        """Test updating optimization status."""
        mock_database_service.execute_query.return_value = None

        await repository.update_optimization_status("test-123", "completed")

        mock_database_service.execute_query.assert_called_once()
        call_args = mock_database_service.execute_query.call_args
        assert "UPDATE" in call_args[0][0].upper()

    @pytest.mark.asyncio
    async def test_delete_optimization_result(self, repository, mock_database_service):
        """Test deleting optimization result."""
        mock_database_service.execute_query.return_value = None

        await repository.delete_optimization_result("test-123")

        mock_database_service.execute_query.assert_called_once()
        call_args = mock_database_service.execute_query.call_args
        assert "DELETE" in call_args[0][0].upper()

    @pytest.mark.asyncio
    async def test_save_parameter_results(self, repository, mock_database_service):
        """Test saving parameter results."""
        mock_database_service.execute_query.return_value = None
        parameter_results = [
            {"parameter_name": "param1", "value": Decimal("0.1"), "score": Decimal("100.0")},
            {"parameter_name": "param2", "value": Decimal("0.2"), "score": Decimal("200.0")}
        ]

        await repository.save_parameter_results("test-opt-123", parameter_results)

        # Should be called once for each parameter result
        assert mock_database_service.execute_query.call_count == len(parameter_results)

    @pytest.mark.asyncio
    async def test_get_parameter_results(self, repository, mock_database_service):
        """Test getting parameter results."""
        mock_results = [
            {"parameter_name": "param1", "value": "0.1", "score": "100.0"},
            {"parameter_name": "param2", "value": "0.2", "score": "200.0"}
        ]
        mock_database_service.fetch_all.return_value = mock_results

        results = await repository.get_parameter_results("test-opt-123")

        assert results == mock_results
        mock_database_service.fetch_all.assert_called_once()


class TestOptimizationRepositoryErrorHandling:
    """Test error handling in repository."""

    @pytest.fixture
    def mock_database_service(self):
        """Create a mock database service that can raise errors."""
        db_service = Mock()
        db_service.execute_query = AsyncMock()
        db_service.fetch_all = AsyncMock()
        db_service.fetch_one = AsyncMock()
        return db_service

    @pytest.fixture
    def repository(self, mock_database_service):
        """Create repository with mocked database."""
        repo = OptimizationRepository(db_service=mock_database_service)
        return repo

    @pytest.mark.asyncio
    async def test_save_optimization_result_database_error(self, repository, mock_database_service):
        """Test handling database errors during save."""
        mock_database_service.execute_query.side_effect = Exception("Database error")

        with pytest.raises(Exception, match="Database error"):
            await repository.save_optimization_result({"test": "data"})

    @pytest.mark.asyncio
    async def test_get_optimization_result_database_error(self, repository, mock_database_service):
        """Test handling database errors during fetch."""
        mock_database_service.fetch_one.side_effect = Exception("Database error")

        with pytest.raises(Exception, match="Database error"):
            await repository.get_optimization_result("test-123")

    @pytest.mark.asyncio
    async def test_list_optimization_results_database_error(self, repository, mock_database_service):
        """Test handling database errors during list."""
        mock_database_service.fetch_all.side_effect = Exception("Database error")

        with pytest.raises(Exception, match="Database error"):
            await repository.list_optimization_results()

    @pytest.mark.asyncio
    async def test_save_with_invalid_data(self, repository, mock_database_service):
        """Test saving with invalid data."""
        # This should be handled by the repository's validation
        invalid_data = None

        with pytest.raises(Exception):
            await repository.save_optimization_result(invalid_data)

    @pytest.mark.asyncio
    async def test_save_with_missing_required_fields(self, repository, mock_database_service):
        """Test saving with missing required fields."""
        incomplete_data = {"optimization_id": "test-123"}  # Missing other required fields

        # Repository should handle this gracefully
        await repository.save_optimization_result(incomplete_data)

        # Should still attempt to save
        mock_database_service.execute_query.assert_called_once()


class TestOptimizationRepositoryFinancialPrecision:
    """Test financial precision handling in repository."""

    @pytest.fixture
    def repository(self):
        """Create repository with mocked database."""
        with patch('src.optimization.repository.DatabaseService') as mock_db:
            mock_instance = Mock()
            mock_instance.execute_query = AsyncMock()
            mock_instance.fetch_one = AsyncMock()
            mock_instance.fetch_all = AsyncMock()
            mock_db.return_value = mock_instance
            repo = OptimizationRepository()
            repo._db_service = mock_instance
            return repo

    @pytest.mark.asyncio
    async def test_save_high_precision_decimals(self, repository):
        """Test saving high precision decimal values."""
        high_precision_data = {
            "optimization_id": "precision-test",
            "algorithm_name": "test",
            "optimal_objective_value": Decimal("123456789.123456789012345"),
            "parameters": {
                "risk_tolerance": Decimal("0.123456789012345678901234567890")
            }
        }

        await repository.save_optimization_result(high_precision_data)

        # Should execute without precision loss
        repository._db_service.execute_query.assert_called_once()

    @pytest.mark.asyncio
    async def test_fetch_preserves_decimal_precision(self, repository):
        """Test that fetching preserves decimal precision."""
        # Mock database returns string representations
        mock_result = {
            "optimization_id": "precision-test",
            "optimal_objective_value": "123456789.123456789012345",
            "parameters": '{"risk_tolerance": "0.123456789012345678901234567890"}'
        }
        repository._db_service.fetch_one.return_value = mock_result

        result = await repository.get_optimization_result("precision-test")

        # Should return the original string format (repository doesn't convert)
        assert result["optimal_objective_value"] == "123456789.123456789012345"

    @pytest.mark.asyncio
    async def test_save_zero_and_negative_values(self, repository):
        """Test saving zero and negative decimal values."""
        edge_case_data = {
            "optimization_id": "edge-test",
            "algorithm_name": "test",
            "optimal_objective_value": Decimal("0.0"),
            "parameters": {
                "negative_param": Decimal("-999.999999"),
                "zero_param": Decimal("0.000000")
            }
        }

        await repository.save_optimization_result(edge_case_data)

        repository._db_service.execute_query.assert_called_once()


class TestOptimizationRepositoryEdgeCases:
    """Test edge cases and boundary conditions."""

    @pytest.fixture
    def repository(self):
        """Create repository with mocked database."""
        with patch('src.optimization.repository.DatabaseService') as mock_db:
            mock_instance = Mock()
            mock_instance.execute_query = AsyncMock()
            mock_instance.fetch_one = AsyncMock()
            mock_instance.fetch_all = AsyncMock()
            mock_db.return_value = mock_instance
            repo = OptimizationRepository()
            repo._db_service = mock_instance
            return repo

    @pytest.mark.asyncio
    async def test_save_empty_parameters(self, repository):
        """Test saving optimization result with empty parameters."""
        empty_params_data = {
            "optimization_id": "empty-test",
            "algorithm_name": "test",
            "optimal_parameters": {},
            "optimal_objective_value": Decimal("100.0")
        }

        await repository.save_optimization_result(empty_params_data)

        repository._db_service.execute_query.assert_called_once()

    @pytest.mark.asyncio
    async def test_list_with_extreme_limits(self, repository):
        """Test listing with extreme limit values."""
        repository._db_service.fetch_all.return_value = []

        # Test with very large limit
        results1 = await repository.list_optimization_results(limit=999999)
        assert results1 == []

        # Test with zero limit
        results2 = await repository.list_optimization_results(limit=0)
        assert results2 == []

        # Test with negative limit (should be handled gracefully)
        results3 = await repository.list_optimization_results(limit=-1)
        assert results3 == []

    @pytest.mark.asyncio
    async def test_get_nonexistent_parameter_results(self, repository):
        """Test getting parameter results for nonexistent optimization."""
        repository._db_service.fetch_all.return_value = []

        results = await repository.get_parameter_results("nonexistent-id")

        assert results == []

    @pytest.mark.asyncio
    async def test_update_status_nonexistent_optimization(self, repository):
        """Test updating status for nonexistent optimization."""
        repository._db_service.execute_query.return_value = None

        # Should not raise error, just execute the query
        await repository.update_optimization_status("nonexistent-id", "completed")

        repository._db_service.execute_query.assert_called_once()

    @pytest.mark.asyncio
    async def test_delete_nonexistent_optimization(self, repository):
        """Test deleting nonexistent optimization."""
        repository._db_service.execute_query.return_value = None

        # Should not raise error, just execute the query
        await repository.delete_optimization_result("nonexistent-id")

        repository._db_service.execute_query.assert_called_once()

    @pytest.mark.asyncio
    async def test_save_parameter_results_empty_list(self, repository):
        """Test saving empty parameter results list."""
        await repository.save_parameter_results("test-opt-123", [])

        # Should not call execute_query for empty list
        repository._db_service.execute_query.assert_not_called()

    @pytest.mark.asyncio
    async def test_concurrent_operations(self, repository):
        """Test that concurrent operations don't interfere."""
        import asyncio

        # Setup different return values
        repository._db_service.fetch_one.side_effect = [
            {"optimization_id": "test-1"},
            {"optimization_id": "test-2"},
            {"optimization_id": "test-3"}
        ]

        # Run multiple gets concurrently
        tasks = [
            repository.get_optimization_result("test-1"),
            repository.get_optimization_result("test-2"),
            repository.get_optimization_result("test-3")
        ]

        results = await asyncio.gather(*tasks)

        assert len(results) == 3
        assert results[0]["optimization_id"] == "test-1"
        assert results[1]["optimization_id"] == "test-2"
        assert results[2]["optimization_id"] == "test-3"